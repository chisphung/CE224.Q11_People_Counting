# CE224.Q11 - People Counting System

A real-time people counting application powered by YOLOv11, featuring ESP32-CAM integration, edge computing with WebSocket streaming, FastAPI backend, and Next.js frontend with live bounding box visualization.

![Python](https://img.shields.io/badge/Python-3.12-blue?logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green?logo=fastapi)
![Next.js](https://img.shields.io/badge/Next.js-14-black?logo=next.js)
![YOLOv11](https://img.shields.io/badge/YOLO-v11-purple)
![ESP32](https://img.shields.io/badge/ESP32-CAM-orange?logo=espressif)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Usage](#-usage)
- [API Documentation](#-api-documentation)
- [Dataset](#-dataset)
- [Contributing](#-contributing)
- [License](#-license)

## âœ¨ Features

- **Real-time People Detection**: Utilizes YOLOv11 for accurate people counting
- **ESP32-CAM Integration**: Wireless camera streaming via WebSocket
- **Edge Computing**: On-device YOLO inference for low-latency processing
- **Live Video Streaming**: Real-time annotated video feed with bounding boxes
- **Web Interface**: Modern, responsive UI built with Next.js and Tailwind CSS
- **RESTful API**: FastAPI backend with automatic OpenAPI documentation
- **Multiple Input Sources**: Support for images, video files, webcam, and RTSP streams
- **Statistics Dashboard**: Track detection history and metrics
- **NCNN Model Support**: Optimized model for CPU inference on edge devices

## ğŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚   ESP32-CAM     â”‚â”€â”€â”€â”€â–¶â”‚  Edge Device    â”‚â”€â”€â”€â”€â–¶â”‚  FastAPI Server â”‚â”€â”€â”€â”€â–¶â”‚  Next.js GUI    â”‚
â”‚   (WebSocket)   â”‚     â”‚  (YOLO Infer)   â”‚     â”‚  (Port 8000)    â”‚     â”‚  (Port 3000)    â”‚
â”‚   Port 8080     â”‚     â”‚  ws_server.py   â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **ESP32-CAM** captures JPEG frames and sends via WebSocket to port 8080
2. **Edge Device** (`ws_server.py`) receives frames, runs YOLOv11 inference
3. **Server** receives counting results + annotated frames via REST API
4. **Frontend** polls server for live stream and displays real-time video

## ğŸ“ Project Structure

```
CE224.Q11_People_Counting/
â”œâ”€â”€ edge_side/
â”‚   â”œâ”€â”€ camera/                    # ESP32-CAM Firmware
â”‚   â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.c            # Camera capture & WebSocket client
â”‚   â”‚   â”‚   â””â”€â”€ camera_pins.h     # Hardware pin definitions
â”‚   â”‚   â”œâ”€â”€ CMakeLists.txt
â”‚   â”‚   â””â”€â”€ sdkconfig
â”‚   â”‚
â”‚   â””â”€â”€ infra/                     # Edge ML Infrastructure
â”‚       â”œâ”€â”€ ws_server.py          # WebSocket server + YOLO inference
â”‚       â”œâ”€â”€ main.py               # CLI inference script
â”‚       â”œâ”€â”€ weights/              # Model weights
â”‚       â”‚   â””â”€â”€ yolov11n_ncnn_model/
â”‚       â”œâ”€â”€ dataset/              # Training data
â”‚       â””â”€â”€ tmp/                  # Temporary output
â”‚
â”œâ”€â”€ server_side/
â”‚   â”œâ”€â”€ backend/                   # FastAPI Backend
â”‚   â”‚   â”œâ”€â”€ main.py               # Application entry
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â””â”€â”€ count_people.py   # API endpoints
â”‚   â”‚   â””â”€â”€ schema/               # Pydantic models
â”‚   â”‚       â””â”€â”€ count_people.py
â”‚   â”‚
â”‚   â””â”€â”€ frontend/                  # Next.js Frontend
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ app/
â”‚       â”‚   â”‚   â””â”€â”€ page.tsx      # Main page with live stream
â”‚       â”‚   â”œâ”€â”€ components/
â”‚       â”‚   â”‚   â”œâ”€â”€ LiveVideoStream.tsx  # Real-time video display
â”‚       â”‚   â”‚   â”œâ”€â”€ BoundingBoxCanvas.tsx
â”‚       â”‚   â”‚   â”œâ”€â”€ ImageUploader.tsx
â”‚       â”‚   â”‚   â””â”€â”€ StatsPanel.tsx
â”‚       â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ package.json
â”‚
â””â”€â”€ requirements.txt               # Python dependencies
```

## ğŸš€ Installation

### Prerequisites

- Python 3.10+
- Node.js 18+ (for frontend)
- ESP-IDF 5.x (for ESP32-CAM firmware)
- Git

### 1. Clone the Repository

```bash
git clone https://github.com/chisphung/CE224.Q11_People_Counting.git
cd CE224.Q11_People_Counting
```

### 2. Set Up Python Environment

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

### 3. Set Up Frontend

```bash
cd server_side/frontend
npm install
```

### 4. Set Up ESP32-CAM (Optional)

```bash
cd edge_side/camera
# Configure Wi-Fi in main/main.c (WIFI_SSID, WIFI_PASS, SERVER_URI)
idf.py build
idf.py flash
```

## ğŸ“– Usage

### Option 1: Full Pipeline (ESP32-CAM â†’ Edge â†’ Server â†’ Frontend)

```bash
# Terminal 1: Start the backend server
cd server_side/backend
python main.py

# Terminal 2: Start the edge WebSocket server
cd edge_side/infra
python ws_server.py --display  # --display to see local preview

# Terminal 3: Start the frontend
cd server_side/frontend
npm run dev

# Power on ESP32-CAM (connects automatically)
```

Open `http://localhost:3000` to see the live video stream with people counting.

### Option 2: Backend API Only

```bash
cd server_side/backend
python main.py
# API available at http://localhost:8000
```

### Option 3: CLI Inference (No server required)

```bash
cd edge_side/infra

# Process a single image
python main.py --source path/to/image.jpg --out tmp/result.jpg

# Process video
python main.py --source path/to/video.mp4 --out-dir ./frames

# Use webcam
python main.py --source 0 --out tmp/latest.jpg
```

### Edge WebSocket Server Options

| Option            | Default                       | Description                               |
| ----------------- | ----------------------------- | ----------------------------------------- |
| `--port`          | 8080                          | WebSocket server port                     |
| `--server`        | `http://localhost:8000`       | Backend server URL                        |
| `--weights`       | `weights/yolov11n_ncnn_model` | Path to model weights                     |
| `--conf`          | 0.25                          | Confidence threshold                      |
| `--device`        | `cpu`                         | Device (`cpu` or `cuda:0`)                |
| `--display`       | False                         | Display annotated frames locally          |
| `--send-interval` | 1.0                           | Interval between server updates (seconds) |

## ğŸ“š API Documentation

### Endpoints

| Method | Endpoint                    | Description                                     |
| ------ | --------------------------- | ----------------------------------------------- |
| `GET`  | `/`                         | API information                                 |
| `GET`  | `/health`                   | Health check                                    |
| `POST` | `/api/v1/count`             | Count people from file path/URL                 |
| `POST` | `/api/v1/count/upload`      | Count people from uploaded image                |
| `POST` | `/api/v1/count/base64`      | Count people from base64 image                  |
| `POST` | `/api/v1/count/edge`        | Receive count from edge device                  |
| `GET`  | `/api/v1/count/latest`      | Get latest count from edge                      |
| `GET`  | `/api/v1/count/history`     | Get counting history                            |
| `GET`  | `/api/v1/stream/frame`      | Get latest annotated frame (for live streaming) |
| `GET`  | `/api/v1/result/{filename}` | Get annotated result image                      |

### Example: Upload Image

```bash
curl -X POST "http://localhost:8000/api/v1/count/upload" \
  -F "file=@image.jpg" \
  -F "conf=0.25"
```

### Example: Get Live Count

```bash
curl "http://localhost:8000/api/v1/count/latest"
```

### Example Response

```json
{
  "success": true,
  "people_count": 5,
  "detections": [
    {
      "class_id": 0,
      "class_name": "person",
      "confidence": 0.92,
      "bbox": [100, 150, 250, 450]
    }
  ],
  "timestamp": "2025-12-25T10:30:00",
  "camera_id": "esp32_cam"
}
```

Interactive API documentation:

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

## ğŸ“Š Dataset

The model is trained on a custom people counting dataset from Roboflow:

- **Classes**: 1 (`people`)
- **Source**: [Roboflow Universe](https://universe.roboflow.com/chris-3k2jo/people_counting-lqqio/dataset/3)
- **License**: CC BY 4.0

## ğŸ›  Technologies

### Hardware

- **ESP32-CAM** - Wi-Fi camera module with OV2640 sensor

### Edge Computing

- **ESP-IDF** - Espressif IoT Development Framework
- **WebSockets** - Real-time bidirectional communication
- **Ultralytics** - YOLOv11 implementation
- **NCNN** - Optimized inference for edge devices

### Backend

- **FastAPI** - Modern Python web framework
- **OpenCV** - Image processing
- **Pydantic** - Data validation

### Frontend

- **Next.js 14** - React framework with App Router
- **TypeScript** - Type-safe JavaScript
- **Tailwind CSS** - Utility-first CSS

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors

- **Chi Phung** - [GitHub](https://github.com/chisphung)

## ğŸ™ Acknowledgments

- [Ultralytics](https://ultralytics.com/) for YOLOv11
- [Roboflow](https://roboflow.com/) for dataset hosting
- [Espressif](https://www.espressif.com/) for ESP32-CAM
- [Vercel](https://vercel.com/) for Next.js

---

<p align="center">
  Made with â¤ï¸ for CE224.Q11
</p>
