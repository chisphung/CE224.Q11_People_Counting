# CE224.Q11 - People Counting System

A real-time people counting application powered by YOLOv11 and WiFi CSI (Channel State Information), featuring ESP32-CAM integration, edge computing with WebSocket streaming, FastAPI backend, and Next.js frontend with live bounding box visualization.

![Python](https://img.shields.io/badge/Python-3.12-blue?logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green?logo=fastapi)
![Next.js](https://img.shields.io/badge/Next.js-14-black?logo=next.js)
![YOLOv11](https://img.shields.io/badge/YOLO-v11-purple)
![ESP32](https://img.shields.io/badge/ESP32-CAM-orange?logo=espressif)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Usage](#-usage)
- [CSI People Counting](#-csi-people-counting)
- [API Documentation](#-api-documentation)
- [Dataset](#-dataset)
- [Contributing](#-contributing)
- [License](#-license)

## âœ¨ Features

- **Real-time People Detection**: Utilizes YOLOv11 for accurate people counting
- **WiFi CSI Sensing**: Non-visual human detection using WiFi signal variations
- **Multi-Modal Fusion**: Combines camera and CSI for improved accuracy
- **ESP32-CAM Integration**: Wireless camera streaming via WebSocket
- **Edge Computing**: On-device YOLO inference for low-latency processing
- **Live Video Streaming**: Real-time annotated video feed with bounding boxes
- **ML Model Training**: Train custom CSI models for people counting
- **Web Interface**: Modern, responsive UI built with Next.js and Tailwind CSS
- **RESTful API**: FastAPI backend with automatic OpenAPI documentation
- **NCNN Model Support**: Optimized model for CPU inference on edge devices

## ğŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚   ESP32-CAM     â”‚â”€â”€â”€â”€â–¶â”‚  Edge Device    â”‚â”€â”€â”€â”€â–¶â”‚  FastAPI Server â”‚â”€â”€â”€â”€â–¶â”‚  Next.js GUI    â”‚
â”‚  Camera + CSI   â”‚     â”‚  (YOLO Infer)   â”‚     â”‚  (Port 8000)    â”‚     â”‚  (Port 3000)    â”‚
â”‚   Port 8080     â”‚     â”‚  ws_server.py   â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚
                                â”‚                       â–¼
                                â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  CSI Training   â”‚
                                  CSI Data      â”‚  (ML Models)    â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **ESP32-CAM** captures JPEG frames + CSI data, sends via WebSocket
2. **Edge Device** (`ws_server.py`) receives frames, runs YOLOv11, forwards CSI
3. **Server** stores CSI data for training, serves results to frontend
4. **Frontend** displays live video stream with real-time counting

## ğŸ“ Project Structure

```
CE224.Q11_People_Counting/
â”œâ”€â”€ edge_side/
â”‚   â”œâ”€â”€ camera/                    # ESP32-CAM Firmware
â”‚   â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.c            # Camera + CSI capture & WebSocket
â”‚   â”‚   â”‚   â””â”€â”€ camera_pins.h     # Hardware pin definitions
â”‚   â”‚   â”œâ”€â”€ sdkconfig             # CSI enabled configuration
â”‚   â”‚   â””â”€â”€ CMakeLists.txt
â”‚   â”‚
â”‚   â””â”€â”€ infra/                     # Edge ML Infrastructure
â”‚       â”œâ”€â”€ ws_server.py          # WebSocket server + YOLO inference
â”‚       â”œâ”€â”€ train_csi_model.py    # CSI ML model training script
â”‚       â”œâ”€â”€ main.py               # CLI inference script
â”‚       â”œâ”€â”€ weights/              # Model weights
â”‚       â”‚   â””â”€â”€ yolov11n_ncnn_model/
â”‚       â”œâ”€â”€ csi_data/             # CSI training data
â”‚       â”‚   â””â”€â”€ training_data.jsonl
â”‚       â””â”€â”€ tmp/                  # Temporary output
â”‚
â”œâ”€â”€ server_side/
â”‚   â”œâ”€â”€ backend/                   # FastAPI Backend
â”‚   â”‚   â”œâ”€â”€ main.py               # Application entry
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ count_people.py   # Camera counting endpoints
â”‚   â”‚   â”‚   â””â”€â”€ csi.py            # CSI data endpoints
â”‚   â”‚   â””â”€â”€ schema/               # Pydantic models
â”‚   â”‚
â”‚   â””â”€â”€ frontend/                  # Next.js Frontend
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ app/
â”‚       â”‚   â”‚   â””â”€â”€ page.tsx      # Main page with live stream
â”‚       â”‚   â”œâ”€â”€ components/
â”‚       â”‚   â”‚   â”œâ”€â”€ LiveVideoStream.tsx
â”‚       â”‚   â”‚   â”œâ”€â”€ BoundingBoxCanvas.tsx
â”‚       â”‚   â”‚   â””â”€â”€ ...
â”‚       â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ package.json
â”‚
â””â”€â”€ requirements.txt               # Python dependencies
```

## ğŸš€ Installation

### Prerequisites

- Python 3.10+
- Node.js 18+ (for frontend)
- ESP-IDF 5.x (for ESP32-CAM firmware)
- Git

### 1. Clone the Repository

```bash
git clone https://github.com/chisphung/CE224.Q11_People_Counting.git
cd CE224.Q11_People_Counting
```

### 2. Set Up Python Environment

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

pip install -r requirements.txt
```

### 3. Set Up Frontend

```bash
cd server_side/frontend
npm install
```

### 4. Set Up ESP32-CAM

```bash
cd edge_side/camera
# Configure Wi-Fi in main/main.c (WIFI_SSID, WIFI_PASS, SERVER_URI)
idf.py build
idf.py flash
```

## ğŸ“– Usage

### Option 1: Full Pipeline (ESP32-CAM â†’ Edge â†’ Server â†’ Frontend)

```bash
# Terminal 1: Start the backend server
cd server_side/backend
python main.py

# Terminal 2: Start the edge WebSocket server
cd edge_side/infra
python ws_server.py --display  # --display for local preview

# Terminal 3: Start the frontend
cd server_side/frontend
npm run dev

# Power on ESP32-CAM (connects automatically)
```

Open `http://localhost:3000` for live video stream with people counting.

### Option 2: CLI Inference

```bash
cd edge_side/infra

# Process image
python main.py --source path/to/image.jpg --out tmp/result.jpg

# Use webcam
python main.py --source 0 --out tmp/latest.jpg
```

## ğŸ“¡ CSI People Counting

WiFi CSI (Channel State Information) enables non-visual human detection by analyzing WiFi signal variations caused by human presence.

### How It Works

1. **ESP32 collects CSI** data from WiFi packets
2. **Edge server forwards** CSI + camera count to backend
3. **Server stores** CSI data with camera-based labels
4. **Train ML model** to predict people count from CSI alone

### Collecting Training Data

```bash
# Start full pipeline (server + edge + ESP32)
# CSI data auto-saves to: edge_side/infra/csi_data/training_data.jsonl

# Check collection stats
curl http://localhost:8000/api/v1/csi/stats
```

### Training a CSI Model

```bash
cd edge_side/infra

# Random Forest (recommended)
python train_csi_model.py \
    --data csi_data/training_data.jsonl \
    --model rf \
    --output csi_model.pkl

# Neural Network
python train_csi_model.py --data csi_data/training_data.jsonl --model nn

# Gradient Boosting
python train_csi_model.py --data csi_data/training_data.jsonl --model gb
```

### CSI Features Extracted

| Feature      | Description                        |
| ------------ | ---------------------------------- |
| Statistical  | Mean, std, min, max, median, range |
| Quartiles    | 25th, 75th percentile              |
| Higher-order | Skewness, kurtosis                 |
| Energy       | Sum and mean of squared amplitudes |
| Variance     | Per-segment variance               |
| Frequency    | FFT-based features                 |
| RSSI         | Signal strength                    |

## ğŸ“š API Documentation

### Camera Endpoints

| Method | Endpoint               | Description               |
| ------ | ---------------------- | ------------------------- |
| `POST` | `/api/v1/count`        | Count from file/URL       |
| `POST` | `/api/v1/count/upload` | Count from uploaded image |
| `POST` | `/api/v1/count/edge`   | Receive from edge device  |
| `GET`  | `/api/v1/count/latest` | Latest count              |
| `GET`  | `/api/v1/stream/frame` | Live frame for streaming  |

### CSI Endpoints

| Method | Endpoint                    | Description           |
| ------ | --------------------------- | --------------------- |
| `POST` | `/api/v1/csi/data`          | Receive CSI data      |
| `GET`  | `/api/v1/csi/stats`         | Collection statistics |
| `GET`  | `/api/v1/csi/buffer`        | Recent CSI samples    |
| `GET`  | `/api/v1/csi/training-data` | Training file info    |

Interactive docs: `http://localhost:8000/docs`

## ğŸ“Š Dataset

Camera model trained on custom people counting dataset from Roboflow:

- **Classes**: 1 (`people`)
- **Source**: [Roboflow Universe](https://universe.roboflow.com/chris-3k2jo/people_counting-lqqio/dataset/3)
- **License**: CC BY 4.0

## ğŸ›  Technologies

### Hardware

- **ESP32-CAM** - Wi-Fi camera with CSI support

### Edge Computing

- **WiFi CSI** - Channel State Information for human sensing
- **YOLOv11** - Object detection
- **NCNN** - Optimized inference

### Backend

- **FastAPI** - Python web framework
- **scikit-learn** - ML model training

### Frontend

- **Next.js 14** - React framework
- **Tailwind CSS** - Styling

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file.

## ğŸ‘¥ Authors

- **Chi Phung** - [GitHub](https://github.com/chisphung)

---

<p align="center">
  Made with â¤ï¸ for CE224.Q11
</p>
